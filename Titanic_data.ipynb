{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports required\n",
    "from pyspark.sql import SparkSession,SQLContext,types\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".master('local') \\\n",
    ".appName('Data cleaning') \\\n",
    ".getOrCreate()\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "import pandas as pd\n",
    "from handyspark import *\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer,VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the dataset\n",
    "file = '/Users/SreeHarsha/Downloads/titanicdataset/titanic_data.csv'\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|   4|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|  58|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|  20|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|  39|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|  14|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|  55|    0|    0|          248706|     16| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|   2|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|     13| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|  31|    1|    0|          345763|     18| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col,size\n",
    "\n",
    "# Count null values in each column of dataset\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16835016835016836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratio of missing values in Age\n",
    "150/df.select('Age').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6722783389450057"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratio of missing values in Cabin\n",
    "599/df.select('Cabin').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the datatype from string to Float( Pyspark ml evaluation metrics handle float values)\n",
    "df = df.withColumn('SibSp',df['SibSp'].cast(FloatType()))\n",
    "df =  df.withColumn('Parch',df['Parch'].cast(FloatType()))\n",
    "df=  df.withColumn('Pclass',df['Pclass'].cast(FloatType()))\n",
    "df =  df.withColumn('Age',df['Age'].cast(FloatType()))\n",
    "df =  df.withColumn('Fare',df['Fare'].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine parch and Sibsp variable into new variable Travelbuds \n",
    "df = df.withColumn('travelbuds', df[\"Parch\"]+df['Sibsp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.withColumn('Survived',df['Survived'].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop unnecessary columns from the dataset\n",
    "df= df.drop('Parch')\n",
    "df= df.drop('Sibsp')\n",
    "df = df.drop('PassengerId')\n",
    "df = df.drop('Ticket')\n",
    "df = df.drop('Name')\n",
    "df = df.drop('Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+--------+------------+\n",
      "|Survived|Pclass|   Sex| Age|   Fare|Embarked|travelbdfuds|\n",
      "+--------+------+------+----+-------+--------+------------+\n",
      "|     0.0|   3.0|  male|22.0|   7.25|       S|         1.0|\n",
      "|     1.0|   1.0|female|38.0|71.2833|       C|         1.0|\n",
      "|     1.0|   3.0|female|26.0|  7.925|       S|         0.0|\n",
      "|     1.0|   1.0|female|35.0|   53.1|       S|         1.0|\n",
      "|     0.0|   3.0|  male|35.0|   8.05|       S|         0.0|\n",
      "|     0.0|   3.0|  male|null| 8.4583|       Q|         0.0|\n",
      "|     0.0|   1.0|  male|54.0|51.8625|       S|         0.0|\n",
      "|     0.0|   3.0|  male| 2.0| 21.075|       S|         4.0|\n",
      "|     1.0|   3.0|female|27.0|11.1333|       S|         2.0|\n",
      "|     1.0|   2.0|female|14.0|30.0708|       C|         1.0|\n",
      "|     1.0|   3.0|female| 4.0|   16.7|       S|         2.0|\n",
      "|     1.0|   1.0|female|58.0|  26.55|       S|         0.0|\n",
      "|     0.0|   3.0|  male|20.0|   8.05|       S|         0.0|\n",
      "|     0.0|   3.0|  male|39.0| 31.275|       S|         6.0|\n",
      "|     0.0|   3.0|female|14.0| 7.8542|       S|         0.0|\n",
      "|     1.0|   2.0|female|55.0|   16.0|       S|         0.0|\n",
      "|     0.0|   3.0|  male| 2.0| 29.125|       Q|         5.0|\n",
      "|     1.0|   2.0|  male|null|   13.0|       S|         0.0|\n",
      "|     0.0|   3.0|female|31.0|   18.0|       S|         1.0|\n",
      "|     1.0|   3.0|female|null|  7.225|       C|         0.0|\n",
      "+--------+------+------+----+-------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the spark dataframe to Handyframe for easier plotting functionalities\n",
    "hdf = df.toHandy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Histogram(x = hdf.cols['Age'][:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age    28.0\n",
       "Name: median, dtype: float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on distribution, we use Median of age to impute missing values due to the skew\n",
    "hdf.cols['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked    S\n",
       "Name: mode, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute Embarked with mode as only 2 missing values\n",
    "hdf.cols['Embarked'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing\n",
    "hdf = hdf.fill(continuous = ['Age'],strategy = ['median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = hdf.fill(categorical = ['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting distributions of Survivors by age\n",
    "# Add histogram data\n",
    "x1 = hdf.filter(hdf['Survived']== 1).cols['Age'][:]\n",
    "x2 = hdf.filter(hdf['Survived']== 0).cols['Age'][:]\n",
    "\n",
    "survived = go.Histogram(\n",
    "    x=x1,\n",
    "    name = 'survived',\n",
    "    opacity=0.75\n",
    ")\n",
    "died = go.Histogram(\n",
    "    x=x2,\n",
    "    name = 'died',\n",
    "    opacity=0.75\n",
    ")\n",
    "\n",
    "data = [survived, died]\n",
    "layout = go.Layout(barmode='overlay')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of survivors by Passenger class\n",
    "data = [go.Bar(x = hdf.cols['Pclass'][:],\n",
    "               y = hdf.cols['Survived'][:])]\n",
    "\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode categorical variables using onehotencoder\n",
    "stringIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndex\")\n",
    "model = stringIndexer.fit(hdf)\n",
    "indexed = model.transform(hdf)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"EmbarkedIndex\", outputCol=\"EmbarkedVec\")\n",
    "encoded = encoder.transform(indexed)\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n",
    "model = stringIndexer.fit(encoded)\n",
    "indexed = model.transform(encoded)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"SexIndex\", outputCol=\"SexVec\")\n",
    "encoded = encoder.transform(indexed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Combine all features into a single vector. This vector acts as input for ml algorithm\n",
    "features = encoded.select([c for c in ['Survived','Pclass','Age','Fare','travelbuds','EmbarkedIndex','EmbarkedVec','SexIndex','SexVec'] ])\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=features.columns, outputCol=\"features\")\n",
    "features_vec = vecAssembler.transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The target variable in spark ml is always named 'label'\n",
    "features_vec = features_vec.withColumnRenamed(\"Survived\", \"label\")\n",
    "features_data = features_vec.select(\"label\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the features into training and test data\n",
    "feat_train, feat_test = features_data.randomSplit([0.9, 0.1], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defing the logistic regression model and Cross validator\n",
    "lr = LogisticRegression(maxIter=20)\n",
    "\n",
    "pipeline = Pipeline(stages=[lr])\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "cross_val = CrossValidator(estimator=pipeline,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=5)  \n",
    "\n",
    "model = cross_val.fit(feat_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.transform(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prediction and metrics\n",
    "predictionLabels = results.select(\"prediction\", \"label\")\n",
    "metrics = BinaryClassificationMetrics(predictionLabels.rdd)\n",
    "metrics.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.areaUnderPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
